{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "   145 /    250\r"
     ]
    }
   ],
   "source": [
    "from audiocraft.models import MusicGen\n",
    "from audiocraft.models import MultiBandDiffusion\n",
    "\n",
    "USE_DIFFUSION_DECODER = False\n",
    "# Using small model, better results would be obtained with `medium` or `large`.\n",
    "model = MusicGen.get_pretrained('facebook/musicgen-small')\n",
    "if USE_DIFFUSION_DECODER:\n",
    "    mbd = MultiBandDiffusion.get_mbd_musicgen()\n",
    "\n",
    "\n",
    "model.set_generation_params(\n",
    "    use_sampling=True,\n",
    "    top_k=5, # 250\n",
    "    duration=5 # 30\n",
    ")\n",
    "\n",
    "import math\n",
    "import torchaudio\n",
    "import torch\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "\n",
    "def get_bip_bip(bip_duration=0.125, frequency=440,\n",
    "                duration=0.5, sample_rate=32000, device=\"cuda\"):\n",
    "    \"\"\"Generates a series of bip bip at the given frequency.\"\"\"\n",
    "    t = torch.arange(\n",
    "        int(duration * sample_rate), device=\"cuda\", dtype=torch.float) / sample_rate\n",
    "    wav = torch.cos(2 * math.pi * 440 * t)[None]\n",
    "    tp = (t % (2 * bip_duration)) / (2 * bip_duration)\n",
    "    envelope = (tp >= 0.5).float()\n",
    "    return wav * envelope\n",
    "\n",
    "from audiocraft.utils.notebook import display_audio\n",
    "from pydub import AudioSegment\n",
    "\n",
    "output = model.generate(\n",
    "    descriptions=[\n",
    "        #'80s pop track with bassy drums and synth',\n",
    "        #'90s rock song with loud guitars and heavy drums',\n",
    "        #'Progressive rock drum and bass solo',\n",
    "        #'Punk Rock song with loud drum and power guitar',\n",
    "        #'Bluesy guitar instrumental with soulful licks and a driving rhythm section',\n",
    "        #'Jazz Funk song with slap bass and powerful saxophone',\n",
    "        'drum and bass beat with intense percussions'\n",
    "    ],\n",
    "    progress=True, return_tokens=True\n",
    ")\n",
    "display_audio(output[0], sample_rate=32000)\n",
    "\n",
    "try:\n",
    "    import IPython.display as ipd  # type: ignore\n",
    "except ImportError:\n",
    "    # Note in a notebook...\n",
    "    pass\n",
    "\n",
    "\n",
    "import torch\n",
    "import torchaudio\n",
    "\n",
    "\n",
    "def dustin(samples: torch.Tensor, sample_rate: int):\n",
    "    \"\"\"Renders an audio player for the given audio samples.\n",
    "\n",
    "    Args:\n",
    "        samples (torch.Tensor): a Tensor of decoded audio samples\n",
    "            with shapes [B, C, T] or [C, T]\n",
    "        sample_rate (int): sample rate audio should be displayed with.\n",
    "    \"\"\"\n",
    "    assert samples.dim() == 2 or samples.dim() == 3\n",
    "\n",
    "    samples = samples.detach().cpu()\n",
    "    if samples.dim() == 2:\n",
    "        samples = samples[None, ...]\n",
    "\n",
    "    for audio in samples:\n",
    "        torchaudio.save('output1.mp3', audio, sample_rate)\n",
    "        # ipd.display(ipd.Audio(audio, rate=sample_rate))\n",
    "\n",
    "dustin(output[0], sample_rate=32000)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "nlp_env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
